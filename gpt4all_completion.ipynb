{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/raph/.local/share/nomic.ai/GPT4All/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/raph/.local/share/nomic.ai/GPT4All/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size = 1838.73 MB\n",
      "llama_model_load_internal: mem required  = 2194.73 MB (+  650.00 MB per state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: max tensor size =    54.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: kv self size  =  650.00 MB\n",
      "llama.cpp: using Vulkan on NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b.ggmlv3.q4_0.bin\", model_path=\"/home/raph/.local/share/nomic.ai/GPT4All\", device=\"gpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the forest of the night,\n",
      "Where the trees stand tall and proud,\n",
      "The moonlight shines upon my face,\n",
      "And I feel its gentle embrace.\n",
      "\n",
      "I hear the rustling leaves below,\n",
      "As they whisper secrets in their own way,\n",
      "And the chirping birds up high,\n",
      "Whose melodies fill the air with light.\n",
      "\n",
      "The scent of flowers fills the air,\n",
      "As the breeze blows soft and sweet,\n",
      "And I feel my heart begin to sing,\n",
      "With the beauty all around.\n",
      "\n",
      "In this moment, I am whole,\n",
      "My soul feels at peace within,\n",
      "And I know that life is but a song,\n",
      "That we must dance to its beat."
     ]
    }
   ],
   "source": [
    "output = model.generate(\"long poem: \", max_tokens=500, streaming=True, temp=0.2)\n",
    "\n",
    "for o in output:\n",
    "    print(o, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
